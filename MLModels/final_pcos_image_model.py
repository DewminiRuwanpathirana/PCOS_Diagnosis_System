# -*- coding: utf-8 -*-
"""Final_PCOS_Image_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u7Qw65WgjP8ugtgRgVZT48ppKGOfMjSv
"""

# Mount Google Drive to access the dataset
from google.colab import drive
drive.mount('/content/drive')

"""# Importing Libraries"""

# Import necessary libraries
import os
import random
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from PIL import Image
from torchvision import transforms, datasets
from torch.utils.data import DataLoader, random_split
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import f1_score, recall_score, precision_score, confusion_matrix
from torch.utils.data import random_split

# Set up the device for GPU or CPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

print(f"Using device: {device}")

"""# Data Loading and Preprocessing"""

class ImageFolderEX(datasets.ImageFolder):
    # Redefine to handle any potential corrupted images
    def __getitem__(self, index):
        path, target = self.samples[index]
        try:
            sample = self.loader(path)
        except:
            return None
        if self.transform is not None:
            sample = self.transform(sample)
        if self.target_transform is not None:
            target = self.target_transform(target)
        return sample, target

# Define the data directory paths
data_dir = "/content/drive/MyDrive/PCOS_Ultrasound_images/train"
test_data_dir = "/content/drive/MyDrive/PCOS_Ultrasound_images/test"

# Define transformations for images (resize and convert to tensor)
transform = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])

# Load datasets with transformation
train_dataset = ImageFolderEX(data_dir, transform=transform)
test_dataset = ImageFolderEX(test_data_dir, transform=transform)

# Print basic dataset information
print('Train samples:', len(train_dataset))
print('Test samples:', len(test_dataset))
print("Classes:", train_dataset.classes)

# Define training and validation split (80:20)
train_size = int(0.8 * len(train_dataset))  # 80% for training
val_size = len(train_dataset) - train_size  # 20% for validation

# Split the dataset into training and validation sets
train_data, val_data = random_split(train_dataset, [train_size, val_size])

print(f"Length of Train Data : {len(train_data)}")
print(f"Length of Validation Data : {len(val_data)}")

# Define DataLoader with custom collate function to ignore None values (corrupted images)
def collate_fn(batch):
    batch = list(filter(lambda x: x is not None, batch))
    return torch.utils.data.dataloader.default_collate(batch)

# Load train and validation data in batches
batch_size = 128
train_loader = DataLoader(train_data, batch_size, shuffle=True, collate_fn=collate_fn, num_workers=2, pin_memory=True)
val_loader = DataLoader(val_data, batch_size*2, collate_fn=collate_fn, num_workers=2, pin_memory=True)
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)

class ImageClassificationBase(nn.Module):
    def training_step(self, batch):
        images, labels = batch
        images = images.to(device)
        labels = labels.to(device)

        out = self(images)                  # Generate predictions
        loss = F.cross_entropy(out, labels) # Calculate training loss
        return loss

    def validation_step(self, batch):
        images, labels = batch
        images = images.to(device)
        labels = labels.to(device)

        out = self(images)                    # Generate predictions
        loss = F.cross_entropy(out, labels)   # Calculate validation loss
        acc = accuracy(out, labels)           # Calculate accuracy
        return {'val_loss': loss.detach(), 'val_acc': acc}

    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses
        batch_accs = [x['val_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies
        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}

    def epoch_end(self, epoch, result):
        print("Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}".format(
            epoch, result['train_loss'], result['train_acc'], result['val_loss'], result['val_acc']))

"""# Model Architecture"""

class PCOSClassifier(ImageClassificationBase):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            nn.Conv2d(3, 12, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(3, 3),

            nn.Conv2d(12, 15, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(3, 3),

            nn.Conv2d(15, 10, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(3, 3),

            nn.Flatten(),
            nn.Linear(810, 2),
        )

    def forward(self, xb):
        return self.network(xb)

# Calculate accuracy
def accuracy(outputs, labels):
    _, preds = torch.max(outputs, dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len(preds))

@torch.no_grad()
def evaluate(model, val_loader):
    model.eval()
    outputs = []
    all_labels = []
    all_preds = []

    for batch in val_loader:
        output = model.validation_step(batch)
        outputs.append(output)

        # Extract labels and predictions for metrics calculation
        images, labels = batch
        images, labels = images.to(device), labels.to(device)
        out = model(images)
        _, preds = torch.max(out, dim=1)
        all_labels.append(labels)
        all_preds.append(preds)

    # Concatenate all labels and predictions
    all_labels = torch.cat(all_labels)
    all_preds = torch.cat(all_preds)

    # Calculate metrics
    f1 = f1_score(all_labels.cpu(), all_preds.cpu(), average='weighted')
    recall = recall_score(all_labels.cpu(), all_preds.cpu(), average='weighted')
    precision = precision_score(all_labels.cpu(), all_preds.cpu(), average='weighted')

    # Get the epoch's loss and accuracy
    epoch_result = model.validation_epoch_end(outputs)
    epoch_result['f1_score'] = f1
    epoch_result['recall'] = recall
    epoch_result['precision'] = precision
    return epoch_result

# Training loop
def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.Adam):
    history = []
    optimizer = opt_func(model.parameters(), lr)
    for epoch in range(epochs):
        # Training phase
        model.train()
        train_losses = []  # List to store training losses
        train_accuracies = []  # List to store training accuracies
        for batch in train_loader:
            images, labels = batch
            images, labels = images.to(device), labels.to(device)

            # Forward pass and loss calculation
            out = model(images)
            loss = F.cross_entropy(out, labels)
            train_losses.append(loss)

            # Backward pass and optimization
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()

            # Calculate training accuracy for the batch
            batch_accuracy = accuracy(out, labels)
            train_accuracies.append(batch_accuracy)

        # Validation phase
        result = evaluate(model, val_loader)
        result['train_loss'] = torch.stack(train_losses).mean().item()
        result['train_acc'] = torch.stack(train_accuracies).mean().item() # Average training accuracy
        model.epoch_end(epoch, result)
        history.append(result)
    return history

"""# Model training process"""

# Initialize and train the model
model = PCOSClassifier().to(device)
num_epochs = 10
learning_rate = 0.001
history = fit(epochs=num_epochs,
              lr=learning_rate,
              model=model,
              train_loader=train_loader,
              val_loader=val_loader)

"""# Evaluation of model outcomes"""

def plot_confusion_matrix(model, val_loader):
    all_labels = []
    all_preds = []

    for batch in val_loader:
        images, labels = batch
        images, labels = images.to(device), labels.to(device)
        out = model(images)
        _, preds = torch.max(out, dim=1)
        all_labels.append(labels)
        all_preds.append(preds)

    # Concatenate all labels and predictions
    all_labels = torch.cat(all_labels)
    all_preds = torch.cat(all_preds)

    # Generate confusion matrix
    cm = confusion_matrix(all_labels.cpu(), all_preds.cpu())
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix')
    plt.show()

# Final evaluation on the validation set
result = evaluate(model, val_loader)
print("Validation Accuracy: {:.4f}, F1 Score: {:.4f}, Precision: {:.4f}, Recall: {:.4f}".format(
    result['val_acc'], result['f1_score'], result['precision'], result['recall']
))

# Plot the confusion matrix
plot_confusion_matrix(model, val_loader)

#save the model
torch.save(model.state_dict(), 'PCOS_detection_{}_epochs_val_acc_{}.pth'.format(num_epochs, history[-1]['val_acc'])) # ex: PCOS_detection_10_epochs_val_acc_85.pth

"""## Plot Training and Validation Accuracy"""

# Plot validation and Training accuracy
def plot_accuracies(history):
    training_accuracies = [x.get('train_acc') for x in history]  # Get training accuracies
    validation_accuracies = [x['val_acc'] for x in history]      # Get validation accuracies

    plt.plot(training_accuracies, '-gx', label='Training Accuracy')  # Plot training accuracy
    plt.plot(validation_accuracies, '-x', label='Validation Accuracy')  # Plot validation accuracy

    plt.xlabel('epoch')
    plt.ylabel('accuracy')
    plt.title('Training and Validation Accuracy')
    plt.legend(['Training', 'Validation'])
    plt.show()

plot_accuracies(history)

"""## Plot Training and Validation Loss"""

# Plot training and validation loss
def plot_losses(history):
    train_losses = [x.get('train_loss') for x in history] # Get training losses
    val_losses = [x['val_loss'] for x in history] # Get validation losses

    plt.plot(train_losses, '-bx') # Plot training loss
    plt.plot(val_losses, '-rx') # Plot validation accuracy
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.title('Training and Validation Loss')
    plt.legend(['Training', 'Validation'])
    plt.show()

plot_losses(history)

"""## ROC Curve"""

def plot_roc_curve(model, val_loader):
    all_labels = []
    all_probs = []

    model.eval()
    with torch.no_grad():
        for batch in val_loader:
            images, labels = batch
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            probs = torch.softmax(outputs, dim=1)[:, 1]  # Probability of class 1

            all_labels.append(labels.cpu().numpy())
            all_probs.append(probs.cpu().numpy())

    all_labels = np.concatenate(all_labels)
    all_probs = np.concatenate(all_probs)

    # Compute ROC curve and AUC score
    fpr, tpr, _ = roc_curve(all_labels, all_probs)
    roc_auc = auc(fpr, tpr)

    # Plot ROC curve
    plt.figure(figsize=(6, 4))
    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')
    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

# Call the function to plot ROC curve
plot_roc_curve(model, val_loader)

# Predict the class for a new image
def predict_img_class(img, model):
    img = img.unsqueeze(0).to(device)
    prediction = model(img)
    _, preds = torch.max(prediction, dim=1)
    return train_dataset.classes[preds[0].item()]

# Test a random image from the test dataset
test_img_path = random.choice(os.listdir('/content/drive/MyDrive/PCOS_Ultrasound_images/test/infected'))
img = Image.open(f'/content/drive/MyDrive/PCOS_Ultrasound_images/test/infected/{test_img_path}')
img = transform(img)
plt.imshow(img.permute(1, 2, 0))

pred = predict_img_class(img, model)
print(f"Predicted Class: {pred}")

import torch
import torch.nn as nn
import torch.nn.functional as F
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from torchvision import transforms
import os
from skimage import morphology

# Load the saved model
model = PCOSClassifier()
model.load_state_dict(torch.load("/content/drive/MyDrive/PCOS_Models/PCOS_detection_10_epochs_val_acc_1.0.pth"))
model.eval()  # Set the model to evaluation mode

# Define image transformation pipeline
transform = transforms.Compose([
    transforms.Resize((256, 256)),  # Resize the image to 256x256
    transforms.ToTensor()  # Convert the image to a PyTorch tensor
])

# Function to detect ovarian cysts in an ultrasound image
def detect_ovarian_cysts(img_tensor):
    # Convert the tensor to a NumPy array and adjust dimensions
    img_np = img_tensor.permute(1, 2, 0).numpy()

    # Convert the image to grayscale if it has 3 channels (RGB)
    img_gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY) if img_np.shape[2] == 3 else img_np[:,:,0]

    # Normalize the grayscale image to the range [0, 255]
    img_norm = cv2.normalize(img_gray, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to enhance contrast
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    img_clahe = clahe.apply(img_norm)

    # Invert the image to make dark regions (cysts) appear bright
    img_inv = 255 - img_clahe

    # Apply adaptive thresholding to create a binary image
    binary = cv2.adaptiveThreshold(img_inv, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 71, -9)

    # Perform morphological opening to remove noise
    opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8), iterations=3)

    # Find contours in the binary image
    contours, _ = cv2.findContours(opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Create a mask to store detected cysts
    cyst_mask = np.zeros_like(img_gray)

    # Filter contours based on area, circularity, and eccentricity
    for contour in contours:
        area = cv2.contourArea(contour)
        # Skip very small or very large regions
        if area < 50 or area > img_gray.shape[0] * img_gray.shape[1] * 0.25:
            continue

        perimeter = cv2.arcLength(contour, True)
        if perimeter == 0:
            continue

        # Calculate circularity: 4π(area/perimeter²)
        circularity = 4 * np.pi * (area / (perimeter * perimeter))
        if circularity < 0.4:  # Skip non-circular shapes
            continue

        # Fit an ellipse to the contour
        if len(contour) < 5:  # Need at least 5 points to fit an ellipse
            continue

        try:
            (x, y), (major, minor), angle = cv2.fitEllipse(contour)
            if minor == 0:
                continue

            # Calculate eccentricity of the ellipse
            eccentricity = np.sqrt(1 - (minor / major) ** 2)
            if eccentricity > 0.85:  # Skip highly elongated shapes
                continue

            # Create a mask for the current contour
            mask = np.zeros_like(img_gray)
            cv2.drawContours(mask, [contour], 0, 1, -1)

            # Calculate the mean intensity of the region in the original image
            mean_intensity = np.mean(img_gray[mask == 1])
            if mean_intensity < 0.5:  # Only consider dark regions (cysts)
                cv2.drawContours(cyst_mask, [contour], 0, 1, -1)
        except:
            # Skip contours that cause errors in ellipse fitting
            continue

    # Apply morphological closing to connect nearby cyst regions
    cyst_mask = morphology.closing(cyst_mask, morphology.disk(2))
    return cyst_mask

# Function to visualize the cyst detection results
def visualize_cyst_detection(img_tensor, title="PCOS Detection"):
    # Convert the tensor to a NumPy array and normalize it for display
    original_img = img_tensor.permute(1, 2, 0).numpy()
    original_img = (original_img - original_img.min()) / (original_img.max() - original_img.min())

    # Detect cysts in the image
    cyst_mask = detect_ovarian_cysts(img_tensor)

    # Create boundaries for the detected cysts
    dilated_mask = morphology.dilation(cyst_mask, morphology.disk(1))
    cyst_boundaries = np.logical_xor(dilated_mask, cyst_mask)

    # Create a copy of the original image for highlighting cysts
    focus_context = original_img.copy()
    alpha = 0.7  # Transparency for cyst highlighting

    # Highlight cysts in red and boundaries in yellow
    for i in range(3):  # Iterate over RGB channels
        if i == 0:  # Red channel
            focus_context[:,:,i] = np.where(cyst_mask == 1, alpha * 1.0 + (1 - alpha) * focus_context[:,:,i], focus_context[:,:,i])
        else:  # Green and Blue channels
            focus_context[:,:,i] = np.where(cyst_mask == 1, alpha * 0.0 + (1 - alpha) * focus_context[:,:,i], focus_context[:,:,i])

        # Add yellow boundaries
        if i < 2:  # Red and Green channels for yellow
            focus_context[:,:,i] = np.where(cyst_boundaries == 1, 1.0, focus_context[:,:,i])
        else:  # Blue channel
            focus_context[:,:,i] = np.where(cyst_boundaries == 1, 0.0, focus_context[:,:,i])

    # Plot the results
    plt.figure(figsize=(16, 10))
    plt.subplot(231)
    plt.imshow(original_img)
    plt.title('Original Ultrasound')
    plt.axis('off')

    plt.subplot(232)
    plt.imshow(cyst_mask, cmap='gray')
    plt.title('Detected Cysts')
    plt.axis('off')

    plt.subplot(233)
    plt.imshow(focus_context)
    plt.title('Final Cyst Detection')
    plt.axis('off')

    return focus_context

# Load a random image from the test folder
image_path = os.path.join("/content/drive/MyDrive/PCOS_Ultrasound_images/test/infected", np.random.choice(os.listdir("/content/drive/MyDrive/PCOS_Ultrasound_images/test/infected")))
img = Image.open(image_path)  # Open the image
img_tensor = transform(img)  # Apply transformations

# Visualize the cyst detection results
final_viz = visualize_cyst_detection(img_tensor)